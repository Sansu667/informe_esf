\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}
\usepackage{amsmath}
\usepackage[T1]{fontenc}

\renewcommand{\tablename}{Tabla}
\renewcommand{\figurename}{Figura}
\renewcommand{\contentsname}{Contenido}

\title{\textbf{Análisis del desempeño de Bilibili Gaming en el World Championship 2024 de League of Legends}}
\author{Valentina Fonseca, Cristian Pérez, Santiago Suarez}
\date{\today}

\begin{document}

\maketitle

<<include=FALSE>>=
library(knitr)
opts_chunk$set(
  concordance=TRUE,
  echo=FALSE,
  warning=FALSE,
  message=FALSE,
  fig.align='center',
  fig.pos='H'
)
@

<<setup, include=FALSE>>=
library(readr)
library(dplyr)
library(ggplot2)
library(kableExtra)
library(gridExtra)
library(rpart)
library(rpart.plot)
@

<<importar_datos>>=
datos <- read.csv("player_statistics_cleaned_final.csv", header = TRUE, stringsAsFactors = FALSE)

names(datos) <- gsub("\\.", "_", names(datos))
names(datos) <- gsub("%", "Percent", names(datos))

names(datos)[names(datos) == "KP_"] <- "KPPercent"
names(datos)[names(datos) == "FB__"] <- "FBPercent"


print(names(datos))
@

<<procesamiento_datos>>=
datos <- datos %>%
  mutate(
    TeamName = as.factor(TeamName),
    PlayerName = as.factor(PlayerName),
    Position = factor(Position, levels = c("Top", "Jungle", "Mid", "Adc", "Support")),
    Games = as.numeric(Games),
    Win_rate = as.numeric(Win_rate),
    KDA = as.numeric(KDA),
    Avg_kills = as.numeric(Avg_kills),
    Avg_deaths = as.numeric(Avg_deaths),
    Avg_assists = as.numeric(Avg_assists),
    GoldPerMin = as.numeric(GoldPerMin),
    KPPercent = as.numeric(KPPercent),
    DamagePercent = as.numeric(DamagePercent)
  )
@

<<resumen_estructura>>=
n_jugadores <- nrow(datos)
n_variables <- ncol(datos)
n_equipos <- length(unique(datos$TeamName))
@

\section{Introducción}

El World Championship 2024 de League of Legends representó uno de los torneos más competitivos de los esports a nivel mundial. Este informe se centra en analizar los factores que pudieron influir en que \textit{Bilibili Gaming} no lograra obtener el campeonato mundial. 

\section{Análisis descriptivo}

\subsection{Descripción general de los datos}
La base de datos analizada contiene información de \textbf{\Sexpr{n_jugadores}} jugadores profesionales de \textbf{\Sexpr{n_equipos}} equipos y \textbf{\Sexpr{n_variables}} variables. Pero antes de continuar es bueno explicar en qué consiste las 12 variables que son importantes para nuestro proposito:
\begin{enumerate}
  \item \textit{TeamName}: Nombre del equipo participante
  \item \textit{PlayerName}: Identificador único del jugador
  \item \textit{Position}: Rol (Top, Jungle, Mid, Adc, Support)
  \item \textit{Games}: Total de partidas disputadas
  \item \textit{Win\_rate}: Tasa de victorias (0-1)
  \item \textit{KDA}: Ratio (Kills + Assists) / Deaths 
  \item \textit{Avg\_kills}: Promedio de eliminaciones 
  \item \textit{Avg\_deaths}: Promedio de muertes 
  \item \textit{Avg\_assists}: Promedio de asistencias 
  \item \textit{GoldPerMin}: Oro por minuto
  \item \textit{DamagePercent}: \% del daño del equipo
  \item \textit{Country}: País de origen
\end{enumerate}

\subsection{Estadísticas descriptivas por equipo}
<<estadisticas_equipos>>=
team_stats <- datos %>%
  group_by(TeamName) %>%
  summarise(
    N = n(),
    WinRate_Mean = mean(Win_rate, na.rm = TRUE),
    KDA_Mean = mean(KDA, na.rm = TRUE),
    GPM_Mean = mean(GoldPerMin, na.rm = TRUE),
    DamagePercent_Mean = mean(DamagePercent, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  arrange(desc(WinRate_Mean))

kable(head(team_stats, 10),
      format = "latex", booktabs = TRUE, digits = 2,
      col.names = c("Equipo", "N. de Jugadores", "Win Rate", "KDA", "GPM", "Dmg %"),
      caption = "Top 10 equipos por tasa de victoria") %>%
  kable_styling(latex_options = c("hold_position", "scale_down"))
@

\subsection{Análisis de Bilibili Gaming}
<<stats_bilibili, results='asis'>>=
bilibili_tabla <- datos %>%
  filter(TeamName == "Bilibili Gaming") %>%
  summarise(
    Jugadores = n(),
    WinRate = mean(Win_rate, na.rm = TRUE),
    KDA = mean(KDA, na.rm = TRUE),
    Kills = mean(Avg_kills, na.rm = TRUE),
    Deaths = mean(Avg_deaths, na.rm = TRUE),
    GPM = mean(GoldPerMin, na.rm = TRUE)
  )

kable(bilibili_tabla, format = "latex", booktabs = TRUE, digits = 2,
      caption = "Estadísticas de Bilibili Gaming") %>%
  kable_styling(latex_options = "hold_position")
@

\subsection{Análisis por posición}
<<grafico_posiciones, fig.cap="KDA por posición", fig.height=3, fig.width=5>>=
ggplot(datos, aes(x = Position, y = KDA, fill = Position)) +
  geom_boxplot() +
  theme_minimal() +
  labs(x = "Posición", y = "KDA") +
  theme(legend.position = "none")
@

El diagrama box plot evidencia diferencias en el rendimiento entre posiciones. Los jugadores de Mid y Adc presentan los valores medianos de KDA más altos, indicando una mayor eficiencia en eliminaciones y asistencias respecto a muertes. En contraste, Top y Support muestran desempeños más modestos, aunque con menor dispersión, lo que sugiere una función más estable y menos dependiente de las estadísticas ofensivas.

<<grafico_winrate_gpm, fig.cap="Win Rate vs Gold Per Min", fig.height=3, fig.width=5>>=
ggplot(datos, aes(x = GoldPerMin, y = Win_rate, color = Position)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "black", linetype = "dashed") +
  theme_minimal() +
  labs(x = "Gold Per Min", y = "Win Rate", color = "Posición") +
  theme(legend.position = "bottom")
@

Se aprecia una asociación positiva débil entre el oro por minuto y la tasa de victorias: la línea de tendencia es ascendente pero de baja pendiente. No obstante, existen excepciones notables (por ejemplo, varios Supports con bajo GPM y alto Win Rate) y la relación varía según la posición. Estas observaciones indican que, si bien la eficiencia económica contribuye al éxito, no explica por sí sola las victorias y su efecto es heterogéneo entre roles.

\section{Análisis inferencial}

\subsection{Diagnóstico visual de distribuciones}
Para validar la robustez de nuestros análisis, inspeccionamos visualmente la distribución de las variables críticas (\textit{KDA} y \textit{GoldPerMin}) comparándolas con una curva normal teórica.

<<distribucion_visual, fig.cap="Distribución de KDA y Gold Per Min con Curva Normal", fig.height=4, fig.width=8>>=
plot_dist <- function(data, var_name, title) {
  ggplot(data, aes_string(x = var_name)) +
    geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "white", alpha = 0.7) +
    stat_function(fun = dnorm, args = list(mean = mean(data[[var_name]], na.rm=TRUE), sd = sd(data[[var_name]], na.rm=TRUE)), color = "red", size = 1) +
    theme_minimal() +
    labs(title = title, y = "Densidad", x = var_name)
}

p1 <- plot_dist(datos, "KDA", "Distribución de KDA")
p2 <- plot_dist(datos, "GoldPerMin", "Distribución de GPM")

grid.arrange(p1, p2, ncol = 2)
@

Visualmente, el \textit{KDA} muestra una ligera asimetría positiva (cola a la derecha), común en métricas de rendimiento donde unos pocos jugadores destacan mucho. El \textit{GoldPerMin} parece ajustarse mejor a la normalidad.

\subsection{Análisis de eficiencia de recursos}
Introducimos una nueva métrica: \textbf{eficiencia de recursos} ($E_R$). A partir de ahora utilizaremos este factor como \textbf{Efficiency}.
$$ E_R = \frac{\text{DamagePercent}}{\text{GoldPerMin}} \times 1000 $$
Esta métrica cuantifica cuánto daño aporta un jugador por cada unidad de oro que consume. Un valor alto indica un jugador que hace "más con menos", optimizando la economía del equipo.

<<analisis_eficiencia, results='asis'>>=
datos <- datos %>% mutate(Efficiency = (DamagePercent / GoldPerMin) * 1000)

test_eff <- t.test(datos$Efficiency[datos$TeamName == "Bilibili Gaming"], mu = mean(datos$Efficiency, na.rm=TRUE))

cat("\\begin{itemize}\n")
cat(paste0("\\item \\textbf{Eficiencia promedio global:} ", round(mean(datos$Efficiency, na.rm=TRUE), 2), "\n"))
cat(paste0("\\item \\textbf{Eficiencia promedio BLG:} ", round(mean(datos$Efficiency[datos$TeamName == "Bilibili Gaming"], na.rm=TRUE), 2), "\n"))
cat(paste0("\\item \\textbf{P-valor de la diferencia:} ", round(test_eff$p.value, 4), "\n"))
cat("\\end{itemize}\n")

cat("\n")
if(test_eff$p.value < 0.05) {
  cat("Bilibili Gaming muestra una eficiencia de recursos estadísticamente diferente al promedio. Esto sugiere un estilo de juego donde la conversión de oro en daño es una prioridad estratégica.")
} else {
  cat("A pesar de su éxito, la eficiencia de recursos de BLG no difiere significativamente del promedio. Su ventaja podría radicar en la obtención bruta de recursos más que en la eficiencia de su uso.")
}
@

\subsection{Intervalos de confianza}
Para ubicar el desempeño de Bilibili Gaming en el contexto global, calculamos los \textbf{intervalos de confianza del 95\%} para la media de cada métrica.
\begin{itemize}
    \item Las \textbf{barras negras} representan el rango donde se encuentra el verdadero promedio global con un 95\% de confianza.
    \item El \textbf{punto rojo} indica el valor observado de Bilibili Gaming.
\end{itemize}
Si el punto rojo cae fuera de las barras, podemos afirmar con un 95\% de seguridad que BLG es significativamente diferente al promedio. Si cae dentro, su desempeño es estadísticamente normal.

<<ci_visual, fig.cap="Comparación de BLG vs Intervalos de confianza globales (95\\%)", fig.height=4, fig.width=6>>=
metrics <- c("KDA", "GoldPerMin", "Efficiency")
ci_data <- data.frame()

for(m in metrics) {
  test <- t.test(datos[[m]])
  blg_val <- mean(datos[[m]][datos$TeamName == "Bilibili Gaming"], na.rm=TRUE)
  ci_data <- rbind(ci_data, data.frame(
    Metric = m,
    Mean_Global = test$estimate,
    Lower = test$conf.int[1],
    Upper = test$conf.int[2],
    BLG_Mean = blg_val
  ))
}

ggplot(ci_data, aes(x = Metric, y = Mean_Global)) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2, size = 1) +
  geom_point(size = 3, shape = 21, fill = "white") + # Media Global
  geom_point(aes(y = BLG_Mean), size = 4, color = "red", shape = 18) + # BLG
  theme_minimal() +
  theme(axis.text.x = element_blank()) + 
  labs(y = "Valor Promedio", x = "", title = "Global (Barras) vs BLG (Punto Rojo)") +
  facet_wrap(~Metric, scales = "free_y")
@

\subsection{Regresión lineal y diagnóstico de residuos}
Ajustamos un modelo de regresión lineal múltiple para cuantificar qué factores determinan el éxito (\textit{Win Rate}). El modelo propuesto es:
$$ \text{Win\_rate} = \beta_0 + \beta_1 \cdot \text{KDA} + \beta_2 \cdot \text{GoldPerMin} + \beta_3 \cdot \text{Efficiency} + \epsilon $$

<<regresion_diagnostico, fig.cap="Diagnóstico del modelo: Residuos y normalidad", fig.height=4, fig.width=8, results='asis'>>=
model_final <- lm(Win_rate ~ KDA + GoldPerMin + Efficiency, data = datos)

coefs <- summary(model_final)$coefficients
df_coefs <- data.frame(
  Estimado = coefs[,1],
  Error_Std = coefs[,2],
  P_Valor = coefs[,4],
  Signif = ifelse(coefs[,4] < 0.05, "*", "")
)
kable(df_coefs, format = "latex", booktabs = TRUE, digits = 4, caption = "Coeficientes del Modelo Final") %>%
  kable_styling(latex_options = "hold_position")

diag_data <- data.frame(
  Fitted = fitted(model_final),
  Residuals = resid(model_final)
)

p1 <- ggplot(diag_data, aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(method = "loess", se = FALSE, color = "darkgray", size = 0.5) +
  labs(title = "Residuos vs Valores ajustados", x = "Valores ajustados", y = "Residuos") +
  theme_minimal()

p2 <- ggplot(diag_data, aes(sample = Residuals)) +
  stat_qq(color = "blue", alpha = 0.6) +
  stat_qq_line(color = "red", linetype = "dashed") +
  labs(title = "Normal Q-Q Plot", x = "Cuantiles teóricos", y = "Cuantiles de la muestra") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)

cat("\n")
cat(paste0("El modelo presenta un $R^2$ ajustado de ", round(summary(model_final)$adj.r.squared, 2), ". Esto significa que el 58\\% de la variabilidad en la tasa de victorias se explica por el KDA, el Oro y la Eficiencia."))
@

\begin{itemize}
    \item \textbf{KDA (Positivo)}: Es el predictor más fuerte. Un mayor KDA está directamente asociado con un mayor Win Rate.
    \item \textbf{GoldPerMin (Positivo)}: Acumular oro también incrementa la probabilidad de victoria, aunque su impacto es menor que el del KDA.
    \item \textbf{Efficiency (Negativo)}: Curiosamente, el coeficiente es negativo. Esto podría deberse a la colinealidad con el Oro, o indicar que equipos que hacen "mucho daño con poco oro" (alta eficiencia) suelen ser equipos que van perdiendo y pelean desde atrás, mientras que los ganadores acumulan tanto oro que su eficiencia nominal baja.
\end{itemize}

Ahora es necesario que expliquemos qué quiere decir aquellos gráficos de la figura 5. El gráfico izquierdo nos muestra que la dispersión es aleatoria alrededor de 0, lo que valida la linealidad del modelo. El gráfico derecho nos muestra que los residuos siguen una distribución normal, lo que valida las pruebas de significancia del modelo.

\subsection{Análisis de varianza (ANOVA)}
Realizamos una prueba ANOVA para verificar si la posición del jugador influye significativamente en la obtención de oro (\textit{GoldPerMin}).
\begin{itemize}
    \item $H_0$: El promedio de oro es igual para todas las posiciones.
    \item $H_1$: Al menos una posición obtiene un promedio de oro diferente.
\end{itemize}

<<anova_test, results='asis'>>=
anova_model <- aov(GoldPerMin ~ Position, data = datos)
anova_res <- summary(anova_model)[[1]]

df_anova <- data.frame(
  Fuente = c("Posición", "Residuales"),
  Df = anova_res$Df,
  Sum_Sq = round(anova_res$`Sum Sq`, 0),
  Mean_Sq = round(anova_res$`Mean Sq`, 0),
  F_Value = c(round(anova_res$`F value`[1], 2), ""),
  P_Value = c(format.pval(anova_res$`Pr(>F)`[1], digits=4, eps=0.0001), "")
)

colnames(df_anova) <- c("Fuente", "Df", "Sum Sq", "Mean Sq", "F Value", "P Value")

df_anova$`P Value` <- gsub("<", "$<$", df_anova$`P Value`)

kable(df_anova, format = "latex", booktabs = TRUE, caption = "Tabla ANOVA: Oro por Posición", escape = FALSE) %>%
  kable_styling(latex_options = "HOLD_position")

cat("\n")
if(anova_res$`Pr(>F)`[1] < 0.05) {
  cat("El valor p es extremadamente bajo ($< 0.05$), por lo que rechazamos la hipótesis nula. Esto confirma estadísticamente que \\textbf{la posición determina la economía}: los carries (ADC, Mid) ganan significativamente más oro que los supports, lo cual es consistente con la estructura del juego.")
} else {
  cat("No se encontraron diferencias significativas entre posiciones.")
}
@

\subsection{Prueba post-hoc de Tukey HSD}
Dado que el ANOVA mostró diferencias significativas, aplicamos la prueba de Tukey HSD para identificar exactamente qué pares de posiciones difieren entre sí.

<<tukey_hsd, results='asis'>>=
tukey_res <- TukeyHSD(anova_model)
tukey_df <- as.data.frame(tukey_res$Position)
tukey_df$Comparison <- rownames(tukey_df)
tukey_df <- tukey_df[, c("Comparison", "diff", "lwr", "upr", "p adj")]

tukey_sig <- tukey_df %>% filter(`p adj` < 0.05)

kable(tukey_sig, format = "latex", booktabs = TRUE, digits = 2, 
      caption = "Diferencias significativas (Tukey HSD) en GPM entre posiciones") %>%
  kable_styling(latex_options = "hold_position")

cat("\n")
cat("La tabla muestra solo las comparaciones que resultaron estadísticamente significativas. Se observa claramente que las posiciones de 'carry' (Adc, Mid) tienen diferencias positivas sustanciales de oro en comparación con el Support y, en menor medida, con el Jungle y Top.")
@

\section{Árboles de decisión}
Para complementar el análisis lineal, implementamos modelos no paramétricos basados en árboles de decisión. Estos modelos nos permiten capturar relaciones no lineales e interacciones entre variables.

\subsection{Árbol de regresión (predicción de Win Rate)}
Ajustamos un árbol de regresión para predecir la tasa de victorias (\textit{Win\_rate}) utilizando las mismas variables que en la regresión lineal: KDA, GoldPerMin y Efficiency.

<<arbol_regresion_calc>>=
set.seed(123)
tree_reg <- rpart(Win_rate ~ KDA + GoldPerMin + Efficiency, data = datos, method = "anova")

opt_cp <- tree_reg$cptable[which.min(tree_reg$cptable[,"xerror"]),"CP"]
tree_reg_pruned <- prune(tree_reg, cp = opt_cp)

pred_reg <- predict(tree_reg_pruned, datos)
rmse_tree <<- sqrt(mean((datos$Win_rate - pred_reg)^2))
mae_tree <<- mean(abs(datos$Win_rate - pred_reg))
@

<<arbol_regresion_plot, fig.cap="Árbol de regresión podado para Win Rate", fig.height=5, fig.width=8>>=
rpart.plot(tree_reg_pruned, main = "Árbol de regresión: Win Rate", type = 3, extra = 101, under = TRUE, faclen = 0)
@

<<print_rmse_text, results='asis'>>=
cat(paste0("El árbol de regresión identifica los puntos de corte optimos en las variables predictoras. El error cuadrático medio (RMSE) del árbol es ", round(rmse_tree, 4), ".\n\n"))

cat("Interpretación del árbol de regresión:\n")
cat("\\begin{itemize}\n")
cat("\\item \\textbf{Dominancia del KDA:} La variable más importante es el KDA. El primer corte se realiza en $KDA < 2.5$, separando a los jugadores con bajo rendimiento (Win Rate promedio $\\approx 0.23$) de los demas.\n")
cat("\\item \\textbf{Alto rendimiento:} Los jugadores con $KDA \\ge 6.4$ tienen la mayor probabilidad de victoria (Win Rate $\\approx 0.76$). Esto confirma que mantener un KDA alto es el indicador más fuerte de éxito.\n")
cat("\\item \\textbf{Rol de la eficiencia:} Para jugadores con KDA intermedio (entre 2.5 y 6.4), la Eficiencia ($E_R$) juega un papel secundario para refinar la predicción.\n")
cat("\\end{itemize}\n")
@

\subsection{Árbol de clasificación (Ganar vs Perder)}
Transformamos la variable continua \textit{Win\_rate} en una variable binaria \textit{Result} (Win si Win\_rate > 0.5, Loss en caso contrario) para entrenar un árbol de clasificación.

<<arbol_clasificacion, fig.cap="Árbol de clasificación podado", fig.height=5, fig.width=8>>=
datos$Result <- ifelse(datos$Win_rate > 0.5, "Win", "Loss")
datos$Result <- as.factor(datos$Result)

tree_class <- rpart(Result ~ KDA + GoldPerMin + Efficiency, data = datos, method = "class")

opt_cp_class <- tree_class$cptable[which.min(tree_class$cptable[,"xerror"]),"CP"]
tree_class_pruned <- prune(tree_class, cp = opt_cp_class)

rpart.plot(tree_class_pruned, main = "Árbol de clasificación: Win/Loss", type = 3, extra = 104, under = TRUE, faclen = 0)

pred_class <- predict(tree_class_pruned, datos, type = "class")
conf_matrix <- table(Real = datos$Result, Predicho = pred_class)
accuracy <<- sum(diag(conf_matrix)) / sum(conf_matrix)
@

<<print_accuracy_text, results='asis'>>=
cat(paste0("La precisión del árbol de clasificación es del ", round(accuracy * 100, 2), "% Este modelo nos permite visualizar reglas de decisión claras:\n\n"))

cat("\\begin{itemize}\n")
cat("\\item \\textbf{Regla de victoria segura:} Si $KDA \\ge 6$, el modelo predice \\textbf{victoria} con una probabilidad muy alta (cercana al 100\\%).\n")
cat("\\item \\textbf{Zona de riesgo:} Si $KDA < 3.7$, la probabilidad de \\textbf{derrota} es muy alta (superior al 90\\%).\n")
cat("\\item \\textbf{Zona intermedia:} Entre KDA 3.7 y 6, el resultado es más incierto y depende de la Eficiencia. Si la eficiencia es baja ($< 0.65$), aun es probable ganar, quizás indicando partidas largas donde se acumula mucho oro pero el KDA no es estelar.\n")
cat("\\end{itemize}\n")
@

\section{Comparación de modelos}
Finalmente, comparamos el desempeño predictivo del modelo de regresión lineal múltiple y el árbol de regresión.

<<comparacion_modelos, results='asis'>>=
pred_lm <- predict(model_final, datos)
rmse_lm <- sqrt(mean((datos$Win_rate - pred_lm)^2))

comparacion <- data.frame(
  Modelo = c("Regresión lineal múltiple", "Árbol de regresión"),
  RMSE = c(rmse_lm, rmse_tree),
  Interpretación = c("Relaciones lineales directas", "Interacciones y cortes no lineales")
)

kable(comparacion, format = "latex", booktabs = TRUE, digits = 4, 
      caption = "Comparación de modelos predictivos (Win Rate)") %>%
  kable_styling(latex_options = "hold_position")

cat("\n")
if(rmse_tree < rmse_lm) {
  cat(paste0("El árbol de regresión presenta un menor error (RMSE = ", round(rmse_tree, 4), ") comparado con la regresión lineal (RMSE = ", round(rmse_lm, 4), "). Esto sugiere que las relaciones entre las métricas de juego y la victoria no son puramente lineales y que existen umbrales críticos."))
} else {
  cat(paste0("La regresión lineal presenta un menor error (RMSE = ", round(rmse_lm, 4), ") comparado con el árbol de regresión (RMSE = ", round(rmse_tree, 4), "). Esto indica que una aproximación lineal es suficiente y más robusta para explicar la variabilidad en la tasa de victorias en este conjunto de datos."))
}
@

\section{Conclusiones}

El objetivo de este informe fue analizar los factores que pudieron influir en que Bilibili Gaming no lograra obtener el campeonato mundial de League of Legends 2024. El análisis, que combinó regresión lineal, árboles de decisión e intervalos de confianza, reveló que el desempeño de BLG fue estadísticamente sobresaliente y consistente con el de un equipo campeón, desafiando la noción de que existieron fallas numéricas estructurales en su juego.

\subsection{Factores clave de influencia}

\textbf{Dominio del KDA como predictor de victoria:}
Los modelos de predicción confirmaron que el KDA es el indicador más potente del éxito competitivo.
\begin{itemize}
    \item Árbol de regresión: Estima que los jugadores con un KDA > 6.4 alcanzan una tasa de victorias promedio del 76\%.
    \item Árbol de clasificación: Indica que superar un KDA de 6 es el umbral crítico para ser clasificado como "Ganador" con una certeza casi absoluta.
    \item El KDA de BLG fue alto (4.12), ubicándose estadísticamente por encima del promedio global. Esto confirma que el equipo tuvo un desempeño ofensivo y de supervivencia de élite.
\end{itemize}

\textbf{Análisis de la eficiencia de recursos ($E_R$):}
Contrario a la hipótesis inicial de una posible ineficiencia, los datos demuestran robustez en este aspecto:
\begin{itemize}
    \item El valor de eficiencia de BLG fue de 0.50, muy cercano al promedio global de 0.52. Al caer dentro del intervalo de confianza global, se confirma que BLG no fue significativamente menos eficiente que el promedio.
    \item El modelo de regresión mostró que los equipos ganadores tienden a tener eficiencias nominales ligeramente menores debido a la gran acumulación de oro. El desempeño de BLG es perfectamente consistente con este patrón, indicando una gestión de recursos normal para un equipo de su calibre.
\end{itemize}

\subsection{Conclusión final}
El análisis estadístico revela que Bilibili Gaming presentó un perfil de rendimiento de élite, sin debilidades numéricas significativas en las métricas evaluadas. Su KDA fue superior al promedio y su eficiencia de recursos fue estadísticamente normal, comportándose como se espera de un equipo ganador.

Por lo tanto, la incapacidad de asegurar el campeonato no puede atribuirse a un déficit en las métricas de desempeño individual o económico. La evidencia sugiere que la derrota en la final se debió a factores intangibles no capturados por estas variables estadísticas, como la toma de decisiones en momentos críticos, la estrategia de selección de campeones (draft) o la ejecución táctica en partidas específicas. Estadísticamente, BLG tuvo el desempeño de un campeón mundial.

\end{document}